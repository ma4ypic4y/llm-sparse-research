#!/usr/bin/env python3
"""
–ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–ø–∞—Ä—Å–Ω–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
"""

import argparse
from pathlib import Path
import torch
from transformers import GPT2LMHeadModel, GPT2Config

from src import (
    print_sparsity_report,
    compare_sparsity_targets,
    calculate_sparsity_stats,
    load_config
)


def main():
    parser = argparse.ArgumentParser(description='Check sparsity of trained model')
    parser.add_argument('--model_dir', type=str, default='exp',
                       help='Directory with trained model')
    parser.add_argument('--config', type=str, default='config.yaml',
                       help='Configuration file (for target sparsity)')
    parser.add_argument('--detailed', action='store_true',
                       help='Show detailed report')

    args = parser.parse_args()

    model_dir = Path(args.model_dir)

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
    print("–ó–∞–≥—Ä—É–∂–∞—é –º–æ–¥–µ–ª—å...")
    try:
        model = GPT2LMHeadModel.from_pretrained(model_dir)
        print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ {model_dir}")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
        print("–ü–æ–ø—Ä–æ–±—É—é —Å–æ–∑–¥–∞—Ç—å –º–æ–¥–µ–ª—å —Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é...")

        config = GPT2Config.from_pretrained('gpt2')
        model = GPT2LMHeadModel(config)
        print("‚ö†Ô∏è  –°–æ–∑–¥–∞–Ω–∞ –Ω–æ–≤–∞—è –º–æ–¥–µ–ª—å (–Ω–µ –æ–±—É—á–µ–Ω–Ω–∞—è)")

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    try:
        config = load_config(args.config)
        target_sparsity = config.get('pruning', {}).get('target_sparsity', 0.5)
        print(f"üìã –¶–µ–ª–µ–≤–∞—è —Å–ø–∞—Ä—Å–Ω–æ—Å—Ç—å –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞: {target_sparsity:.1%}")
    except Exception as e:
        print(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥: {e}")
        target_sparsity = 0.5
        print(f"üìã –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ü–µ–ª–µ–≤–∞—è —Å–ø–∞—Ä—Å–Ω–æ—Å—Ç—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {target_sparsity:.1%}")

    print("\n" + "="*60)
    print("–ê–ù–ê–õ–ò–ó –°–ü–ê–†–°–ù–û–°–¢–ò –ú–û–î–ï–õ–ò")
    print("="*60)

    # –ë—ã—Å—Ç—Ä–∞—è —Å–≤–æ–¥–∫–∞
    stats = calculate_sparsity_stats(model)

    print(f"\nüéØ –¶–ï–õ–ï–í–ê–Ø –°–ü–ê–†–°–ù–û–°–¢–¨: {target_sparsity:.1%}")
    print(f"üìä –¢–ï–ö–£–©–ê–Ø –°–ü–ê–†–°–ù–û–°–¢–¨:")
    print(f"   - –ü—Ä—É–Ω–∏–º—ã–µ –≤–µ—Å–∞: {stats['prunable_weights_sparsity']:.3%}")
    print(f"   - –í—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {stats['all_params_sparsity']:.3%}")

    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å —Ü–µ–ª—å—é
    analysis = compare_sparsity_targets(model, target_sparsity)
    print(f"\nüìà –ü–†–û–ì–†–ï–°–°: {analysis['progress']} –æ—Ç —Ü–µ–ª–∏")
    print(f"üîç –°–¢–ê–¢–£–°: {analysis['status']}")

    print(f"\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
    for rec in analysis['recommendations']:
        print(f"   ‚Ä¢ {rec}")

    # –ö—Ä–∞—Ç–∫–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    totals = stats['totals']
    print(f"\nüìä –ü–ê–†–ê–ú–ï–¢–†–´:")
    print(f"   ‚Ä¢ –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ: {totals['all_parameters']:,}")
    print(f"   ‚Ä¢ –ü—Ä—É–Ω–∏–º—ã–µ: {totals['prunable_parameters']:,} ({totals['prunable_ratio']:.1%})")
    print(f"   ‚Ä¢ –ó–∞–Ω—É–ª–µ–Ω–Ω—ã–µ: {totals['zero_prunable_parameters']:,}")

    # –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –µ—Å–ª–∏ –∑–∞–ø—Ä–æ—à–µ–Ω
    if args.detailed:
        print_sparsity_report(model, "–î–ï–¢–ê–õ–¨–ù–´–ô –û–¢–ß–ï–¢ –ü–û –°–ü–ê–†–°–ù–û–°–¢–ò")

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –º–µ—Ä—Ç–≤—ã–º –Ω–µ–π—Ä–æ–Ω–∞–º
        dead_neurons = stats['dead_neurons_stats']
        if dead_neurons:
            print("\nüß† –ê–ù–ê–õ–ò–ó –ú–ï–†–¢–í–´–• –ù–ï–ô–†–û–ù–û–í:")
            total_dead_output = sum(dn['dead_output_neurons'] for dn in dead_neurons.values())
            total_output = sum(dn['total_output_neurons'] for dn in dead_neurons.values())
            print(f"   ‚Ä¢ –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–µ—Ä—Ç–≤—ã—Ö –≤—ã—Ö–æ–¥–Ω—ã—Ö –Ω–µ–π—Ä–æ–Ω–æ–≤: {total_dead_output}")
            print(f"   ‚Ä¢ –û–±—â–∏–π –ø—Ä–æ—Ü–µ–Ω—Ç –º–µ—Ä—Ç–≤—ã—Ö –Ω–µ–π—Ä–æ–Ω–æ–≤: {total_dead_output/total_output:.2%}")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—Ä–æ–±–ª–µ–º—ã
    print(f"\nüîç –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê:")
    issues = []

    if stats['prunable_weights_sparsity'] == 0 and target_sparsity > 0:
        issues.append("‚ùå –°–ø–∞—Ä—Å–Ω–æ—Å—Ç—å —Ä–∞–≤–Ω–∞ –Ω—É–ª—é –ø—Ä–∏ –Ω–µ–Ω—É–ª–µ–≤–æ–π —Ü–µ–ª–∏ - –ø—Ä—É–Ω–∏–Ω–≥ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç")

    if stats['prunable_weights_sparsity'] > target_sparsity * 1.2:
        issues.append("‚ö†Ô∏è  –°–ø–∞—Ä—Å–Ω–æ—Å—Ç—å –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –ø—Ä–µ–≤—ã—à–∞–µ—Ç —Ü–µ–ª—å")

    dead_neurons = stats['dead_neurons_stats']
    if dead_neurons:
        max_dead = max(dn['dead_output_ratio'] for dn in dead_neurons.values())
        if max_dead > 0.7:
            issues.append("üö® –û—á–µ–Ω—å –≤—ã—Å–æ–∫–∏–π –ø—Ä–æ—Ü–µ–Ω—Ç –º–µ—Ä—Ç–≤—ã—Ö –Ω–µ–π—Ä–æ–Ω–æ–≤ - –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –¥–µ–≥—Ä–∞–¥–∞—Ü–∏—è")
        elif max_dead > 0.4:
            issues.append("‚ö†Ô∏è  –í—ã—Å–æ–∫–∏–π –ø—Ä–æ—Ü–µ–Ω—Ç –º–µ—Ä—Ç–≤—ã—Ö –Ω–µ–π—Ä–æ–Ω–æ–≤ - –≤–æ–∑–º–æ–∂–Ω–∞ –¥–µ–≥—Ä–∞–¥–∞—Ü–∏—è")

    if not issues:
        print("   ‚úÖ –ü—Ä–æ–±–ª–µ–º –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ")
    else:
        for issue in issues:
            print(f"   {issue}")

    print(f"\n{'='*60}")
    print("üìÅ –î–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ: python check_sparsity.py --detailed")
    print("üìä –î–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å –≥—Ä–∞—Ñ–∏–∫–∞–º–∏: python analyze_results.py")
    print(f"{'='*60}\n")


if __name__ == '__main__':
    main()