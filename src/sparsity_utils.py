"""
–í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —É—Ç–∏–ª–∏—Ç—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å–ø–∞—Ä—Å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏
"""

import torch
import torch.nn as nn
from typing import Dict, Tuple, List, Any


def calculate_sparsity_stats(model: nn.Module) -> Dict[str, Any]:
    """
    –í—ã—á–∏—Å–ª—è–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Å–ø–∞—Ä—Å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏

    Returns:
        Dict —Å –∫–ª—é—á–∞–º–∏:
        - all_params_sparsity: —Å–ø–∞—Ä—Å–Ω–æ—Å—Ç—å –≤—Å–µ—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        - prunable_weights_sparsity: —Å–ø–∞—Ä—Å–Ω–æ—Å—Ç—å —Ç–æ–ª—å–∫–æ –ø—Ä—É–Ω–∏–º—ã—Ö –≤–µ—Å–æ–≤
        - layer_wise_sparsity: —Å–ø–∞—Ä—Å–Ω–æ—Å—Ç—å –ø–æ —Å–ª–æ—è–º
        - dead_neurons_stats: —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –º–µ—Ä—Ç–≤—ã—Ö –Ω–µ–π—Ä–æ–Ω–æ–≤
        - parameter_counts: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤
    """
    stats = {}

    # 1. –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    total_all_params = 0
    zero_all_params = 0
    total_prunable_params = 0
    zero_prunable_params = 0

    # 2. –°–ø–∞—Ä—Å–Ω–æ—Å—Ç—å –ø–æ —Å–ª–æ—è–º
    layer_sparsity = {}

    # 3. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –º–µ—Ä—Ç–≤—ã—Ö –Ω–µ–π—Ä–æ–Ω–æ–≤
    dead_neurons = {}

    # 4. –ü–æ–¥—Å—á–µ—Ç —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    param_counts = {
        'embedding': 0,
        'layernorm': 0,
        'linear': 0,
        'conv': 0,
        'bias': 0,
        'other': 0
    }

    for name, param in model.named_parameters():
        if not param.requires_grad:
            continue

        param_size = param.numel()
        zero_count = (param.data == 0).sum().item()

        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        total_all_params += param_size
        zero_all_params += zero_count

        # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        if 'embed' in name.lower():
            param_counts['embedding'] += param_size
        elif 'norm' in name.lower():
            param_counts['layernorm'] += param_size
        elif 'bias' in name.lower():
            param_counts['bias'] += param_size
        elif 'weight' in name:
            # –ü–æ–ª—É—á–∞–µ–º —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏–π –º–æ–¥—É–ª—å
            try:
                parent_module = model
                for part in name.split('.')[:-1]:
                    parent_module = getattr(parent_module, part)

                if isinstance(parent_module, nn.Linear):
                    param_counts['linear'] += param_size
                    # –≠—Ç–æ –ø—Ä—É–Ω–∏–º—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä
                    total_prunable_params += param_size
                    zero_prunable_params += zero_count

                    # –°–ø–∞—Ä—Å–Ω–æ—Å—Ç—å —Å–ª–æ—è
                    layer_sparsity[name] = zero_count / param_size

                    # –ê–Ω–∞–ª–∏–∑ –º–µ—Ä—Ç–≤—ã—Ö –Ω–µ–π—Ä–æ–Ω–æ–≤
                    w = param.data
                    if w.dim() == 2:  # –ú–∞—Ç—Ä–∏—Ü–∞ –≤–µ—Å–æ–≤ Linear —Å–ª–æ—è
                        dead_out = (w == 0).all(dim=1).sum().item()  # –ú–µ—Ä—Ç–≤—ã–µ –≤—ã—Ö–æ–¥–Ω—ã–µ –Ω–µ–π—Ä–æ–Ω—ã
                        dead_in = (w == 0).all(dim=0).sum().item()   # –ú–µ—Ä—Ç–≤—ã–µ –≤—Ö–æ–¥–Ω—ã–µ —Å–≤—è–∑–∏
                        dead_neurons[name] = {
                            'dead_output_neurons': dead_out,
                            'dead_input_connections': dead_in,
                            'total_output_neurons': w.shape[0],
                            'total_input_connections': w.shape[1],
                            'dead_output_ratio': dead_out / w.shape[0],
                            'dead_input_ratio': dead_in / w.shape[1]
                        }

                elif isinstance(parent_module, nn.Conv2d):
                    param_counts['conv'] += param_size
                    total_prunable_params += param_size
                    zero_prunable_params += zero_count
                    layer_sparsity[name] = zero_count / param_size
                else:
                    param_counts['other'] += param_size
            except:
                param_counts['other'] += param_size
        else:
            param_counts['other'] += param_size

    # –°–æ–±–∏—Ä–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    stats['all_params_sparsity'] = zero_all_params / (total_all_params + 1e-8)
    stats['prunable_weights_sparsity'] = zero_prunable_params / (total_prunable_params + 1e-8)
    stats['layer_wise_sparsity'] = layer_sparsity
    stats['dead_neurons_stats'] = dead_neurons
    stats['parameter_counts'] = param_counts

    stats['totals'] = {
        'all_parameters': total_all_params,
        'prunable_parameters': total_prunable_params,
        'zero_all_parameters': zero_all_params,
        'zero_prunable_parameters': zero_prunable_params,
        'prunable_ratio': total_prunable_params / (total_all_params + 1e-8)
    }

    return stats


def print_sparsity_report(model: nn.Module, title: str = "–û—Ç—á–µ—Ç –ø–æ —Å–ø–∞—Ä—Å–Ω–æ—Å—Ç–∏"):
    """–ü–µ—á–∞—Ç–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –ø–æ —Å–ø–∞—Ä—Å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏"""
    stats = calculate_sparsity_stats(model)

    print(f"\n{'='*60}")
    print(f"{title}")
    print(f"{'='*60}")

    # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print(f"\nüìä –û–ë–©–ê–Ø –°–ü–ê–†–°–ù–û–°–¢–¨:")
    print(f"   –í—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {stats['all_params_sparsity']:.3%}")
    print(f"   –ü—Ä—É–Ω–∏–º—ã–µ –≤–µ—Å–∞: {stats['prunable_weights_sparsity']:.3%}")

    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã
    totals = stats['totals']
    print(f"\nüî¢ –ü–ê–†–ê–ú–ï–¢–†–´:")
    print(f"   –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ: {totals['all_parameters']:,}")
    print(f"   –ü—Ä—É–Ω–∏–º—ã–µ: {totals['prunable_parameters']:,} ({totals['prunable_ratio']:.1%})")
    print(f"   –ó–∞–Ω—É–ª–µ–Ω–Ω—ã–µ (–≤—Å–µ): {totals['zero_all_parameters']:,}")
    print(f"   –ó–∞–Ω—É–ª–µ–Ω–Ω—ã–µ (–ø—Ä—É–Ω–∏–º—ã–µ): {totals['zero_prunable_parameters']:,}")

    # –†–∞–∑–±–∏–≤–∫–∞ –ø–æ —Ç–∏–ø–∞–º
    param_counts = stats['parameter_counts']
    print(f"\nüìã –†–ê–ó–ë–ò–í–ö–ê –ü–û –¢–ò–ü–ê–ú:")
    for param_type, count in param_counts.items():
        if count > 0:
            print(f"   {param_type.capitalize()}: {count:,}")

    # –¢–æ–ø-10 —Å–∞–º—ã—Ö —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω—ã—Ö —Å–ª–æ–µ–≤
    layer_sparsity = stats['layer_wise_sparsity']
    if layer_sparsity:
        print(f"\nüèÜ –¢–û–ü-10 –°–ê–ú–´–• –†–ê–ó–†–ï–ñ–ï–ù–ù–´–• –°–õ–û–ï–í:")
        sorted_layers = sorted(layer_sparsity.items(), key=lambda x: x[1], reverse=True)
        for name, sparsity in sorted_layers[:10]:
            print(f"   {name}: {sparsity:.3%}")

    # –ú–µ—Ä—Ç–≤—ã–µ –Ω–µ–π—Ä–æ–Ω—ã
    dead_neurons = stats['dead_neurons_stats']
    if dead_neurons:
        print(f"\n‚ò†Ô∏è  –ú–ï–†–¢–í–´–ï –ù–ï–ô–†–û–ù–´ (—Ç–æ–ø-5 –ø–æ –≤—ã—Ö–æ–¥–Ω—ã–º):")
        sorted_dead = sorted(dead_neurons.items(),
                           key=lambda x: x[1]['dead_output_ratio'], reverse=True)
        for name, dead_stats in sorted_dead[:5]:
            print(f"   {name}: {dead_stats['dead_output_neurons']}/{dead_stats['total_output_neurons']} "
                  f"({dead_stats['dead_output_ratio']:.1%})")

    print(f"{'='*60}\n")


def compare_sparsity_targets(model: nn.Module, target_sparsity: float) -> Dict[str, str]:
    """
    –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Ç–µ–∫—É—â—É—é —Å–ø–∞—Ä—Å–Ω–æ—Å—Ç—å —Å —Ü–µ–ª–µ–≤–æ–π –∏ –¥–∞–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

    Returns:
        Dict —Å –∞–Ω–∞–ª–∏–∑–æ–º –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏
    """
    stats = calculate_sparsity_stats(model)
    current_sparsity = stats['prunable_weights_sparsity']

    analysis = {
        'current_sparsity': f"{current_sparsity:.3%}",
        'target_sparsity': f"{target_sparsity:.3%}",
        'progress': f"{current_sparsity / target_sparsity:.1%}",
        'status': '',
        'recommendations': []
    }

    progress_ratio = current_sparsity / target_sparsity

    if progress_ratio < 0.1:
        analysis['status'] = '–ù–∞—á–∞–ª—å–Ω–∞—è —Å—Ç–∞–¥–∏—è'
        analysis['recommendations'].append('–ü—Ä—É–Ω–∏–Ω–≥ —Ç–æ–ª—å–∫–æ –Ω–∞—á–∞–ª—Å—è, —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ')
    elif progress_ratio < 0.5:
        analysis['status'] = '–ê–∫—Ç–∏–≤–Ω—ã–π –ø—Ä—É–Ω–∏–Ω–≥'
        analysis['recommendations'].append('–ü—Ä—É–Ω–∏–Ω–≥ –∏–¥–µ—Ç –ø–æ –ø–ª–∞–Ω—É')
    elif progress_ratio < 0.9:
        analysis['status'] = '–ü—Ä–∏–±–ª–∏–∂–µ–Ω–∏–µ –∫ —Ü–µ–ª–∏'
        analysis['recommendations'].append('–ë–æ–ª—å—à–∞—è —á–∞—Å—Ç—å –ø—Ä—É–Ω–∏–Ω–≥–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞')
    elif progress_ratio < 1.1:
        analysis['status'] = '–¶–µ–ª—å –¥–æ—Å—Ç–∏–≥–Ω—É—Ç–∞'
        analysis['recommendations'].append('–°–ø–∞—Ä—Å–Ω–æ—Å—Ç—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ü–µ–ª–∏')
    else:
        analysis['status'] = '–ü—Ä–µ–≤—ã—à–µ–Ω–∏–µ —Ü–µ–ª–∏'
        analysis['recommendations'].append('–°–ø–∞—Ä—Å–Ω–æ—Å—Ç—å –≤—ã—à–µ —Ü–µ–ª–µ–≤–æ–π - –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é')

    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ dead neurons
    dead_neurons = stats['dead_neurons_stats']
    if dead_neurons:
        max_dead_ratio = max(dn['dead_output_ratio'] for dn in dead_neurons.values())
        if max_dead_ratio > 0.5:
            analysis['recommendations'].append('‚ö†Ô∏è –í—ã—Å–æ–∫–∏–π –ø—Ä–æ—Ü–µ–Ω—Ç –º–µ—Ä—Ç–≤—ã—Ö –Ω–µ–π—Ä–æ–Ω–æ–≤ - –≤–æ–∑–º–æ–∂–Ω–∞ –¥–µ–≥—Ä–∞–¥–∞—Ü–∏—è')
        elif max_dead_ratio > 0.3:
            analysis['recommendations'].append('–£–º–µ—Ä–µ–Ω–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–µ—Ä—Ç–≤—ã—Ö –Ω–µ–π—Ä–æ–Ω–æ–≤')

    return analysis